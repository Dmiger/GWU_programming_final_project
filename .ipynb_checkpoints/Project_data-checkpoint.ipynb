{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Obtain Main Data: web scraping\n",
    "\n",
    "We scraped apartment data from www.apartment.com for 5 cities in Big D.C. Area, including Washington (D.C.), Arlington (VA), Alexandria (VA), Bethesda (MD) and Silver Spring (MD) then save them as individual csv files for further exploration. (using python, pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import time\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a new function to get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getData(url):\n",
    "    \"\"\"\n",
    "    Input: Dictionary containing URLs of first result page\n",
    "    Output: Two csv files summarizing the data from results\n",
    "    Returns: Nothing\n",
    "    \"\"\"\n",
    "    \n",
    "    apartments = []\n",
    "    i = 0 # Key to identify restaurants\n",
    "    pages = range(1,29)   # Range of strings to add to URL to go to next result page\n",
    "    \n",
    "    \n",
    "    for page in pages:   # Get results one page at a time\n",
    "        time.sleep(0.1)\n",
    "        url1 = url+str(page)+'/'  # URL to search\n",
    "        request = requests.get(url1)\n",
    "        html = request.text\n",
    "        soup = bs(html,\"html.parser\")    \n",
    "        results1 = soup.findAll('article', {\"class\" : \"diamond placard\"})\n",
    "        results2 = soup.findAll('article', {\"class\" : \"platinum placard\"})\n",
    "        results3 = soup.findAll('article', {\"class\" : \"gold placard\"})\n",
    "        results4 = soup.findAll('article', {\"class\" : \"silver placard\"})\n",
    "        results5 = soup.findAll('article', {\"class\" : \"prosumer placard\"})\n",
    "        results6 = soup.findAll('article', {\"class\" : \"basic placard\"})\n",
    "        results = results1 + results2 + results3 + results4 + results5 + results6\n",
    "\n",
    "        for result in results:  \n",
    "            apartments.append({})  \n",
    "            apt_name = result.findAll('a', {\"class\" : \"placardTitle js-placardTitle\"})\n",
    "            apartments[i]['Name'] = apt_name[0].getText()\n",
    "            address = result.findAll('div', {\"class\" : \"location\"})\n",
    "            address = address[0].getText()\n",
    "            splits = address.split(',')\n",
    "            if len(splits) > 2:\n",
    "                apartments[i]['Address'] = splits[0]\n",
    "                apartments[i]['City'] = splits[1]\n",
    "                apartments[i]['State'] = splits[2].split()[0]\n",
    "                apartments[i]['Zip'] = splits[2].split()[1]\n",
    "            else:\n",
    "                apartments[i]['Address'] = apt_name[0].getText()\n",
    "                apartments[i]['City'] = splits[0].strip()\n",
    "                apartments[i]['State'] = splits[1].split()[0]\n",
    "                if len(splits[1].split()) > 1:\n",
    "                    apartments[i]['Zip'] = int(splits[1].split()[1])\n",
    "                else:\n",
    "                    apartments[i]['Zip'] = ''\n",
    "            last_update = result.findAll('span', {\"class\" : \"listingFreshness\"})\n",
    "            apartments[i]['Last update'] = last_update[0].getText().strip()            \n",
    "            images = result.findAll('span', {\"class\" : \"js-spnImgCount\"})\n",
    "            if len(images) > 0:\n",
    "                apartments[i]['Image count'] = images[0].getText()\n",
    "            else:\n",
    "                apartments[i]['Image count'] = 'Not specified'\n",
    "\n",
    "            price = result.findAll('span', {\"class\" : \"altRentDisplay\"})\n",
    "            if '-' in price[0].getText():\n",
    "                apartments[i]['Rent'] = price[0].getText().split('-')[1].replace('$','').strip()\n",
    "            else:\n",
    "                apartments[i]['Rent'] = price[0].getText().replace('$','')\n",
    "            if 'Call' in apartments[i]['Rent']:\n",
    "                apartments[i]['Rent'] = ''\n",
    "            else:\n",
    "                apartments[i]['Rent'] = int(apartments[i]['Rent'].replace(',',''))\n",
    "\n",
    "            style = result.findAll('span', {\"class\" : \"unitLabel propertyStyle\"})\n",
    "            if len(style) == 0:\n",
    "                style = result.findAll('span', {\"class\" : \"unitLabel\"})\n",
    "                if 'Studio' in style[0].getText():\n",
    "                    if len(style[0].getText().split()) < 2:\n",
    "                        apartments[i]['Num bedrooms'] = 0\n",
    "                    else:\n",
    "                        apartments[i]['Num bedrooms'] = style[0].getText().split()[2]\n",
    "                else:\n",
    "                    if '-' in style[0].getText():\n",
    "                        apartments[i]['Num bedrooms'] = style[0].getText().split()[0].split('-')[1]\n",
    "                    else:\n",
    "                        apartments[i]['Num bedrooms'] = style[0].getText().split()[0]\n",
    "            else:\n",
    "                apartments[i]['Num bedrooms'] = 'N/A'\n",
    "            \n",
    "            pet_results = {}\n",
    "            if (len(result.findAll('ul', {\"class\" : \"amenities\"}))) > 0:\n",
    "                pet_results['Dogs'] = result.findAll('li', {\"class\" : \"petIcon\"})\n",
    "                pet_results['Cats'] = result.findAll('li', {\"class\" : \"catIcon\"})\n",
    "                if (len(pet_results['Dogs']) + len(pet_results['Cats']) > 1):\n",
    "                    apartments[i]['Pets Allowed'] = 'Yes'\n",
    "                else:\n",
    "                    apartments[i]['Pets Allowed'] = 'No'\n",
    "            else:\n",
    "                apartments[i]['Pets Allowed'] = 'Contact Management'\n",
    "            i+=1\n",
    "    return apartments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 Cities we are targeting to obtain data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mydata1 = getData('http://www.apartments.com/arlington-va/') \n",
    "mydata2 = getData('http://www.apartments.com/washington-dc/')\n",
    "mydata3 = getData('http://www.apartments.com/alexandria-va/')\n",
    "mydata4 = getData('http://www.apartments.com/bethesda-md/')\n",
    "mydata5 = getData('http://www.apartments.com/silver-spring-md/')\n",
    "#print(mydata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Rent Data to \" apartments.csv \" file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('apartments.csv', 'w', newline = '') as file1:\n",
    "    fieldnames = ['Name','Address','City','State','Zip','Last update','Image count','Num bedrooms','Rent','Pets Allowed']\n",
    "    writer = csv.DictWriter(file1, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for i in mydata1:\n",
    "        writer.writerow(i)\n",
    "        \n",
    "with open('apartments.csv', 'a', newline = '') as file1:\n",
    "    fieldnames = ['Name','Address','City','State','Zip','Last update','Image count','Num bedrooms','Rent','Pets Allowed']\n",
    "    writer = csv.DictWriter(file1,fieldnames=fieldnames)\n",
    "    for i in mydata2:\n",
    "        writer.writerow(i)\n",
    "\n",
    "with open('apartments.csv', 'a', newline = '') as file1:\n",
    "    fieldnames = ['Name','Address','City','State','Zip','Last update','Image count','Num bedrooms','Rent','Pets Allowed']\n",
    "    writer = csv.DictWriter(file1, fieldnames=fieldnames)\n",
    "    for i in mydata3:\n",
    "        writer.writerow(i)\n",
    "        \n",
    "with open('apartments.csv', 'a', newline = '') as file1:\n",
    "    fieldnames = ['Name','Address','City','State','Zip','Last update','Image count','Num bedrooms','Rent','Pets Allowed']\n",
    "    writer = csv.DictWriter(file1, fieldnames=fieldnames)\n",
    "    for i in mydata4:\n",
    "        writer.writerow(i)\n",
    "\n",
    "with open('apartments.csv', 'a', newline = '') as file1:\n",
    "    fieldnames = ['Name','Address','City','State','Zip','Last update','Image count','Num bedrooms','Rent','Pets Allowed']\n",
    "    writer = csv.DictWriter(file1, fieldnames=fieldnames)\n",
    "    for i in mydata5:\n",
    "        writer.writerow(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the outlook of csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1. Name\n",
      "\t<class 'str'>\n",
      "\tNulls: False\n",
      "\tUnique values: 2099\n",
      "\t5 most frequent values:\n",
      "\t\tTopaz House:\t19\n",
      "\t\tThe Whitney:\t19\n",
      "\t\tFlats at Bethesda Avenue:\t19\n",
      "\t\tGallery Bethesda:\t19\n",
      "\t\tRosedale Park Apartments:\t19\n",
      "\tMax length: 45\n",
      "  2. Address\n",
      "\t<class 'str'>\n",
      "\tNulls: False\n",
      "\tUnique values: 2102\n",
      "\t5 most frequent values:\n",
      "\t\t7001 Arlington Rd:\t19\n",
      "\t\t4918 Saint Elmo Ave:\t19\n",
      "\t\t8200 Wisconsin Ave:\t19\n",
      "\t\t4710 Bethesda Ave:\t19\n",
      "\t\t4523-4525 Sangamore Rd:\t19\n",
      "\tMax length: 45\n",
      "  3. City\n",
      "\t<class 'str'>\n",
      "\tNulls: False\n",
      "\tUnique values: 10\n",
      "\t5 most frequent values:\n",
      "\t\tWashington:\t698\n",
      "\t\tBethesda:\t593\n",
      "\t\tAlexandria:\t505\n",
      "\t\tArlington:\t499\n",
      "\t\tSilver Spring:\t476\n",
      "\tMax length: 13\n",
      "  4. State\n",
      "\t<class 'str'>\n",
      "\tNulls: False\n",
      "\tValues: MD, VA, CT, MI, DC\n",
      "  5. Zip\n",
      "\t<class 'int'>\n",
      "\tNulls: True\n",
      "\tMin: 6514\n",
      "\tMax: 49503\n",
      "\tSum: 59831010\n",
      "\tMean: 21149.17285259809\n",
      "\tMedian: 20902\n",
      "\tStandard Deviation: 1072.617236372584\n",
      "\tUnique values: 60\n",
      "\t5 most frequent values:\n",
      "\t\t20814:\t429\n",
      "\t\t20910:\t173\n",
      "\t\t22201:\t114\n",
      "\t\t22304:\t101\n",
      "\t\t20904:\t89\n",
      "  6. Last update\n",
      "\t<class 'str'>\n",
      "\tNulls: False\n",
      "\tUnique values: 18\n",
      "\t5 most frequent values:\n",
      "\t\t3 hrs:\t827\n",
      "\t\tNew:\t522\n",
      "\t\t2 wks:\t341\n",
      "\t\t1 day:\t325\n",
      "\t\t10 hrs:\t171\n",
      "\tMax length: 6\n",
      "  7. Image count\n",
      "\t<class 'str'>\n",
      "\tNulls: False\n",
      "\tUnique values: 92\n",
      "\t5 most frequent values:\n",
      "\t\tNot specified:\t1893\n",
      "\t\t21:\t64\n",
      "\t\t37:\t53\n",
      "\t\t46:\t40\n",
      "\t\t17:\t34\n",
      "\tMax length: 13\n",
      "  8. Num bedrooms\n",
      "\t<class 'int'>\n",
      "\tNulls: True\n",
      "\tMin: 0\n",
      "\tMax: 6\n",
      "\tSum: 3611\n",
      "\tMean: 2.279671717171717\n",
      "\tMedian: 2.0\n",
      "\tStandard Deviation: 0.8192389257615244\n",
      "\tUnique values: 7\n",
      "\t5 most frequent values:\n",
      "\t\t2:\t717\n",
      "\t\t3:\t562\n",
      "\t\t1:\t212\n",
      "\t\t4:\t64\n",
      "\t\t0:\t25\n",
      "  9. Rent\n",
      "\t<class 'int'>\n",
      "\tNulls: True\n",
      "\tMin: 677\n",
      "\tMax: 42000\n",
      "\tSum: 8149302\n",
      "\tMean: 2933.51403887689\n",
      "\tMedian: 2400.0\n",
      "\tStandard Deviation: 1865.0950342178144\n",
      "\tUnique values: 686\n",
      "\t5 most frequent values:\n",
      "\t\t2200:\t48\n",
      "\t\t2600:\t38\n",
      "\t\t2250:\t38\n",
      "\t\t1750:\t37\n",
      "\t\t1800:\t36\n",
      " 10. Pets Allowed\n",
      "\t<class 'str'>\n",
      "\tNulls: False\n",
      "\tValues: Yes, No, Contact Management\n",
      "\n",
      "Row count: 2830\n"
     ]
    }
   ],
   "source": [
    "!csvstat apartments.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--------------------------------------+------------------+------------+-------+-------+-------------+-------------+--------------+------+---------------|\r\n",
      "|  Name                                | Address          | City       | State | Zip   | Last update | Image count | Num bedrooms | Rent | Pets Allowed  |\r\n",
      "|--------------------------------------+------------------+------------+-------+-------+-------------+-------------+--------------+------+---------------|\r\n",
      "|  The Millennium at Metropolitan Park | 1330 S Fair St   |  Arlington | VA    | 22202 | New         | 60          | 2            | 6305 | Yes           |\r\n",
      "|  Parc Rosslyn                        | 1531 N Pierce St |  Arlington | VA    | 22209 | New         | 68          | 3            | 3701 | Yes           |\r\n",
      "|--------------------------------------+------------------+------------+-------+-------+-------------+-------------+--------------+------+---------------|\r\n"
     ]
    }
   ],
   "source": [
    "!csvcut apartments.csv | head -3 | csvlook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain Complementary Data: adding Income by zip code data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Objective: Converting xls file obtained from IRS ( https://www.irs.gov/uac/soi-tax-stats-individual-income-tax-statistics-zip-code-data-soi ) into csv file; read it to the pandas Dataframe and keep only the zipcode and income columns, and integrate it with the \"apartments.csv\" file generated from the webcraping process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# concatenate the 2 csv files that shows the US national income status, save it to income_df\n",
    "df1 = pd.read_csv(\"2014_incometax_part1.csv\",names = None, index_col=False)\n",
    "df2 = pd.read_csv(\"2014_incometax_part2.csv\",names = None, index_col=False)\n",
    "df_income = pd.concat([df1, df2], axis=0)\n",
    "\n",
    "# select and save only the unique zip codes as referential list of zip \n",
    "apt_df = pd.read_csv(\"apartments.csv\",names = None, index_col=False)\n",
    "apt_df = apt_df.Zip.unique()\n",
    "zip = apt_df.tolist()\n",
    "\n",
    "# select income based on zipcodes in the \"zip\" list and save as df_match\n",
    "df_match = df_income[df_income['ZIPCODE'].isin(zip)] \n",
    "df_match = df_match[['A00100','ZIPCODE','N1','STATE']]\n",
    "df_match = df_match.rename(columns = {'ZIPCODE':'Zip','A00100':'Income','N1':'Num_of_Households'})\n",
    "df_match[['Income', 'Zip','Num_of_Households']] = df_match[['Income', 'Zip','Num_of_Households']].astype(int)\n",
    "\n",
    "#join df_match to df with \"Zip\" as the key to get df_full and save to csv file\n",
    "df = pd.read_csv('apartments.csv', names = None, index_col = False)\n",
    "df_full = pd.merge(df,df_match[['Income','Zip','Num_of_Households']], on = [\"Zip\"], how = 'inner')\n",
    "df_full[['Zip','Num_of_Households']] = df_full[['Zip','Num_of_Households']].astype(int)\n",
    "df_full.to_csv('apartments.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the outlook of csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--------------------------------------+-----------------+------------+-------+-------+-------------+-------------+--------------+--------+--------------+---------+--------------------|\r\n",
      "|  Name                                | Address         | City       | State | Zip   | Last update | Image count | Num bedrooms | Rent   | Pets Allowed | Income  | Num_of_Households  |\r\n",
      "|--------------------------------------+-----------------+------------+-------+-------+-------------+-------------+--------------+--------+--------------+---------+--------------------|\r\n",
      "|  The Millennium at Metropolitan Park | 1330 S Fair St  |  Arlington | VA    | 22202 | New         | 60          | 2.0          | 6305.0 | Yes          | 1379382 | 13230              |\r\n",
      "|  RiverHouse                          | 1400 S Joyce St |  Arlington | VA    | 22202 | 3 hrs       | 59          | 3.0          | 2684.0 | Yes          | 1379382 | 13230              |\r\n",
      "|--------------------------------------+-----------------+------------+-------+-------+-------------+-------------+--------------+--------+--------------+---------+--------------------|\r\n"
     ]
    }
   ],
   "source": [
    "!csvcut apartments.csv | head -3 | csvlook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain Complementary Data: adding cordinates generated from address, using geocoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geocoder\n",
    "import numpy as np\n",
    "#import time\n",
    "\n",
    "# create a list of address\n",
    "df=pd.read_csv('apartments.csv', names = None, index_col = False)\n",
    "df1 = df[['Address','City','State']].astype(str).sum(axis=1)\n",
    "address = df1.tolist()  \n",
    "\n",
    "# create a numpy array of coordinates generated by Geocoder with address\n",
    "coordinates= []\n",
    "latitude = []\n",
    "longitude = []\n",
    "for i in address:\n",
    "    #time.sleep(0.1)\n",
    "    g = geocoder.google(i)\n",
    "    a = g.latlng\n",
    "    coordinates.append(a)\n",
    "\n",
    "for i in coordinates:\n",
    "    latitude.append(coordinates[i][0])\n",
    "    longitude.append(coordinates[i][1])\n",
    "latarray = np.asarray(latitude)\n",
    "lngarray = np.asarray(longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create new columns- \"latitude\" and \"longitude\" in dataset\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"apartments.csv\", names=None, index_col=False)\n",
    "df['latitude'] = pd.DataFrame(latarray)\n",
    "df['longitude'] = pd.DataFrame(lngarray)\n",
    "df.to_csv(\"apartments.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the outlook of csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!csvcut apartments_updated.csv | head - | csvlook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain Data: count distance to the nearest metro stations based on coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getFileNames():\n",
    "    \"\"\"\n",
    "    Input = None\n",
    "    Returns = list of all JSON files in current directory\n",
    "    \"\"\"\n",
    "    import os\n",
    "    included_extenstions = ['json'] ;\n",
    "    file_names = [fn for fn in os.listdir(os.getcwd())\n",
    "        if any([fn.endswith(ext)\n",
    "        for ext in included_extenstions])];\n",
    "    return file_names\n",
    "\n",
    "\n",
    "def readMetroData(file):\n",
    "    import json\n",
    "    with open(file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "\n",
    "def getCoords(metro_data):\n",
    "    metro_stations = [metro_data[line]['Stations'] for line in metro_data]\n",
    "    metro_stops = []\n",
    "    for i in range(len(metro_stations)):\n",
    "        metro_stops+= metro_stations[i]\n",
    "\n",
    "    coords = [(stop['Lat'],stop['Lon']) for stop in metro_stops]\n",
    "    return coords\n",
    "\n",
    "\n",
    "def readCSV(filename):\n",
    "    import csv\n",
    "    with open(filename, 'r') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        apartments = []\n",
    "        for row in reader:\n",
    "            apartments.append(row)\n",
    "    return apartments\n",
    "\n",
    "\n",
    "def calculateDistance(coord1, coord2):\n",
    "    import math\n",
    "    R = 6371000\n",
    "    latitude1 = coord1[0]\n",
    "    longitude1 = coord1[1]\n",
    "    \n",
    "    latitude2 = coord2[0]\n",
    "    longitude2 = coord2[1]\n",
    "    \n",
    "    lat1 = math.radians(latitude1)\n",
    "    lat2 = math.radians(latitude2)\n",
    "    delta_lat = math.radians(latitude1 - latitude2)\n",
    "    delta_lon = math.radians(longitude1 - longitude2)\n",
    "    \n",
    "    x = delta_lon * math.cos((lat1+lat2)/2)\n",
    "    y = delta_lat\n",
    "    d = math.sqrt(x*x + y*y) * R\n",
    "    return d\n",
    "\n",
    "\n",
    "def writeData(apartment_data):\n",
    "    import csv\n",
    "    with open('apartments_full.csv', 'w', newline = '') as f:\n",
    "        fieldnames = ['Name','Address','City','State','Zip','Style','Last update','Image count','Num bedrooms','Rent','Pets Allowed','Latitude','Longitude','Income','Num_of_Households','Metro Distance']\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for apt in apartment_data:\n",
    "            writer.writerow(apt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "files = getFileNames() \n",
    "\n",
    "metro_lines = {}\n",
    "for file in files:    \n",
    "    metro_lines[file.replace('Metro_','').replace('.json','')] = readMetroData(file)\n",
    "\n",
    "metro_coords = getCoords(metro_lines)\n",
    "\n",
    "apartments = readCSV('apartments_geocoded.csv')\n",
    "\n",
    "for apt in apartments:\n",
    "    distances = []\n",
    "    for station in metro_coords:\n",
    "        distances.append(calculateDistance((float(apt['Latitude']),float(apt['Longitude'])), station))\n",
    "    apt['Metro Distance'] = min(distances)\n",
    "    if min(distances) > 9041:\n",
    "        apt['Metro Distance'] = ''\n",
    "\n",
    "\n",
    "writeData(apartments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|---------------------------+-------------------------+-------------+-------+-------+-------+-------------+-------------+--------------+--------+--------------------+--------------------+------------+---------+-------------------+---------------------|\r\n",
      "|  Name                     | Address                 | City        | State | Zip   | Style | Last update | Image count | Num bedrooms | Rent   | Pets Allowed       | Latitude           | Longitude  | Income  | Num_of_Households | Metro Distance      |\r\n",
      "|---------------------------+-------------------------+-------------+-------+-------+-------+-------------+-------------+--------------+--------+--------------------+--------------------+------------+---------+-------------------+---------------------|\r\n",
      "|  Fifty Three-Thirty Three | 5333 Connecticut Ave NW |  Washington | DC    | 20015 |       | New         | 28          | 2.0          | 3700.0 | Yes                | 38.960584999999995 | -77.072666 | 1729694 | 7640              | 1150.349297292806   |\r\n",
      "|  Brittany Apartments      | 5432 Connecticut Ave NW |  Washington | DC    | 20015 |       | 5 hrs       | 22          | 2.0          | 2250.0 | Contact Management | 38.962871          | -77.074726 | 1729694 | 7640              | 1000.4429699566624  |\r\n",
      "|---------------------------+-------------------------+-------------+-------+-------+-------+-------------+-------------+--------------+--------+--------------------+--------------------+------------+---------+-------------------+---------------------|\r\n"
     ]
    }
   ],
   "source": [
    "!csvcut apartments_full.csv | head -3 |csvlook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check and clean NULL values and mismatched values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  8. Image count\n",
      "\t<class 'str'>\n",
      "\tNulls: False\n",
      "\tUnique values: 92\n",
      "\t5 most frequent values:\n",
      "\t\tNot specified:\t1871\n",
      "\t\t21:\t64\n",
      "\t\t37:\t53\n",
      "\t\t46:\t41\n",
      "\t\t53:\t33\n",
      "\tMax length: 13\n",
      "  9. Num bedrooms\n",
      "\t<class 'float'>\n",
      "\tNulls: True\n",
      "\tMin: 0.0\n",
      "\tMax: 6.0\n",
      "\tSum: 3597.0\n",
      "\tMean: 2.2737041719342606\n",
      "\tMedian: 2.0\n",
      "\tStandard Deviation: 0.8125462521319246\n",
      "\tUnique values: 7\n",
      "\t5 most frequent values:\n",
      "\t\t2.0:\t718\n",
      "\t\t3.0:\t570\n",
      "\t\t1.0:\t208\n",
      "\t\t4.0:\t55\n",
      "\t\t0.0:\t27\n",
      " 10. Rent\n",
      "\t<class 'float'>\n",
      "\tNulls: True\n",
      "\tMin: 677.0\n",
      "\tMax: 42000.0\n",
      "\tSum: 8176615.0\n",
      "\tMean: 2965.765324628219\n",
      "\tMedian: 2450.0\n",
      "\tStandard Deviation: 1870.8726124304494\n",
      "\tUnique values: 684\n",
      "\t5 most frequent values:\n",
      "\t\t2200.0:\t43\n",
      "\t\t2250.0:\t42\n",
      "\t\t3100.0:\t36\n",
      "\t\t1750.0:\t36\n",
      "\t\t1850.0:\t35\n",
      " 14. Income\n",
      "\t<class 'int'>\n",
      "\tNulls: False\n",
      "\tMin: 110195\n",
      "\tMax: 4097407\n",
      "\tSum: 5582835799\n",
      "\tMean: 1988189.3871082622\n",
      "\tMedian: 1942951.0\n",
      "\tStandard Deviation: 850404.3775364348\n",
      "\tUnique values: 59\n",
      "\t5 most frequent values:\n",
      "\t\t2569860:\t447\n",
      "\t\t1942951:\t182\n",
      "\t\t1923599:\t116\n",
      "\t\t2580059:\t113\n",
      "\t\t2086732:\t97\n",
      " 16. Metro Distance\n",
      "\t<class 'float'>\n",
      "\tNulls: True\n",
      "\tMin: 29.3301372248525\n",
      "\tMax: 8928.001495063747\n",
      "\tSum: 4588810.514806745\n",
      "\tMean: 1649.4645991397356\n",
      "\tMedian: 909.3166367601966\n",
      "\tStandard Deviation: 1755.8859004224814\n",
      "\tUnique values: 1853\n",
      "\t5 most frequent values:\n",
      "\t\t1590.670938666832:\t20\n",
      "\t\t1736.3158552298357:\t19\n",
      "\t\t720.9006338555847:\t19\n",
      "\t\t469.8222609981309:\t19\n",
      "\t\t738.093250395573:\t19\n",
      "\n",
      "Row count: 2808\n"
     ]
    }
   ],
   "source": [
    "! csvstat -c8,9,10,14,16 apartments_full.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"apartments_full.csv\", names = None, index_col=False, encoding = \"ISO-8859-1\")\n",
    "# drop unrelated rows \n",
    "to_drop = ['CT', 'MI']\n",
    "df1 = df[~df['State'].isin(to_drop)]\n",
    "# clean out the null values and save it as 'apartments_nonull.csv'\n",
    "df1 = df[~df['Num bedrooms'].isnull()]\n",
    "df1 = df[~df['Rent'].isnull()]\n",
    "df1 = df[~df['Image count'].isnull()]\n",
    "df1 = df[~df['Metro Distance'].isnull()]\n",
    "df1 = df[~df['Income'].isnull()]\n",
    "df1 = df[~df['Image count'].isin(['Not specified'])]\n",
    "df1.to_csv('apartments_nonull.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# DC AREA RENT ANALYSIS -- Group 6\n",
    "## DNSC 6211: PROGRAMMING FOR ANALYTICS\n",
    "\n",
    "* Dmitry Chudinovskikh\n",
    "* Patrick Steeves \n",
    "* Daniel Swart \n",
    "* Szuying Yang \n",
    "* Xin Yuan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# INTRODUCTION\n",
    "\n",
    "### OBJECTIVE: \n",
    "- Predicting the rent using the predictors below.\n",
    "\n",
    "\n",
    "### PREDICTORS: \n",
    "- Num. of bedrooms \n",
    "- Website image count \n",
    "- Income by zip code \n",
    "- Amenities offered (air-conditioning availability, or washer-dryer, pets permission, parking, dishwasher) \n",
    "- Distance to the nearest metro station\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Obtain Data and Data Formatting\n",
    "\n",
    "## Data Sources\n",
    "\n",
    "- Apartments.com for DC, Arlington, Alexandria, Bethesda, Silver Spring\n",
    "- Individual Income Tax Statistics by ZIP Code Data  \n",
    "- WMATA JSON data for metro stations location \n",
    "\n",
    "## Method \n",
    "\n",
    "- Web Scraping in python\n",
    "- Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def getData(url):\n",
    "    \"\"\"\n",
    "    Input: Dictionary containing URLs of first result page\n",
    "    Output: Two csv files summarizing the data from results\n",
    "    Returns: Nothing\n",
    "    \"\"\"\n",
    "    \n",
    "    apartments = []\n",
    "    i = 0 # Key to identify restaurants\n",
    "    pages = range(1,29)   # Range of strings to add to URL to go to next result page\n",
    "    \n",
    "    \n",
    "    for page in pages:   # Get results one page at a time\n",
    "        time.sleep(0.1)\n",
    "        url1 = url+str(page)+'/'  # URL to search\n",
    "        request = requests.get(url1)\n",
    "        html = request.text\n",
    "        soup = bs(html,\"html.parser\")    \n",
    "        results1 = soup.findAll('article', {\"class\" : \"diamond placard\"})\n",
    "        results2 = soup.findAll('article', {\"class\" : \"platinum placard\"})\n",
    "        results3 = soup.findAll('article', {\"class\" : \"gold placard\"})\n",
    "        results4 = soup.findAll('article', {\"class\" : \"silver placard\"})\n",
    "        results5 = soup.findAll('article', {\"class\" : \"prosumer placard\"})\n",
    "        results6 = soup.findAll('article', {\"class\" : \"basic placard\"})\n",
    "        results = results1 + results2 + results3 + results4 + results5 + results6\n",
    "\n",
    "        for result in results:  \n",
    "            apartments.append({})  \n",
    "            apt_name = result.findAll('a', {\"class\" : \"placardTitle js-placardTitle\"})\n",
    "            apartments[i]['Name'] = apt_name[0].getText()\n",
    "            address = result.findAll('div', {\"class\" : \"location\"})\n",
    "            address = address[0].getText()\n",
    "            splits = address.split(',')\n",
    "            if len(splits) > 2:\n",
    "                apartments[i]['Address'] = splits[0]\n",
    "                apartments[i]['City'] = splits[1]\n",
    "                apartments[i]['State'] = splits[2].split()[0]\n",
    "                apartments[i]['Zip'] = splits[2].split()[1]\n",
    "            else:\n",
    "                apartments[i]['Address'] = apt_name[0].getText()\n",
    "                apartments[i]['City'] = splits[0].strip()\n",
    "                apartments[i]['State'] = splits[1].split()[0]\n",
    "                if len(splits[1].split()) > 1:\n",
    "                    apartments[i]['Zip'] = int(splits[1].split()[1])\n",
    "                else:\n",
    "                    apartments[i]['Zip'] = ''\n",
    "            last_update = result.findAll('span', {\"class\" : \"listingFreshness\"})\n",
    "            apartments[i]['Last update'] = last_update[0].getText().strip()            \n",
    "            images = result.findAll('span', {\"class\" : \"js-spnImgCount\"})\n",
    "            if len(images) > 0:\n",
    "                apartments[i]['Image count'] = images[0].getText()\n",
    "            else:\n",
    "                apartments[i]['Image count'] = 'Not specified'\n",
    "\n",
    "            price = result.findAll('span', {\"class\" : \"altRentDisplay\"})\n",
    "            if '-' in price[0].getText():\n",
    "                apartments[i]['Rent'] = price[0].getText().split('-')[1].replace('$','').strip()\n",
    "            else:\n",
    "                apartments[i]['Rent'] = price[0].getText().replace('$','')\n",
    "            if 'Call' in apartments[i]['Rent']:\n",
    "                apartments[i]['Rent'] = ''\n",
    "            else:\n",
    "                apartments[i]['Rent'] = int(apartments[i]['Rent'].replace(',',''))\n",
    "\n",
    "            style = result.findAll('span', {\"class\" : \"unitLabel propertyStyle\"})\n",
    "            if len(style) == 0:\n",
    "                style = result.findAll('span', {\"class\" : \"unitLabel\"})\n",
    "                if 'Studio' in style[0].getText():\n",
    "                    if len(style[0].getText().split()) < 2:\n",
    "                        apartments[i]['Num bedrooms'] = 0\n",
    "                    else:\n",
    "                        apartments[i]['Num bedrooms'] = style[0].getText().split()[2]\n",
    "                else:\n",
    "                    if '-' in style[0].getText():\n",
    "                        apartments[i]['Num bedrooms'] = style[0].getText().split()[0].split('-')[1]\n",
    "                    else:\n",
    "                        apartments[i]['Num bedrooms'] = style[0].getText().split()[0]\n",
    "            else:\n",
    "                apartments[i]['Num bedrooms'] = 'N/A'\n",
    "            \n",
    "            pet_results = {}\n",
    "            if (len(result.findAll('ul', {\"class\" : \"amenities\"}))) > 0:\n",
    "                pet_results['Dogs'] = result.findAll('li', {\"class\" : \"petIcon\"})\n",
    "                pet_results['Cats'] = result.findAll('li', {\"class\" : \"catIcon\"})\n",
    "                if (len(pet_results['Dogs']) + len(pet_results['Cats']) > 1):\n",
    "                    apartments[i]['Pets Allowed'] = 'Yes'\n",
    "                else:\n",
    "                    apartments[i]['Pets Allowed'] = 'No'\n",
    "            else:\n",
    "                apartments[i]['Pets Allowed'] = 'Contact Management'\n",
    "            i+=1\n",
    "    return apartments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# concatenate the 2 csv files that shows the US national income status, save it to income_df\n",
    "df1 = pd.read_csv(\"2014_incometax_part1.csv\",names = None, index_col=False)\n",
    "df2 = pd.read_csv(\"2014_incometax_part2.csv\",names = None, index_col=False)\n",
    "df_income = pd.concat([df1, df2], axis=0)\n",
    "\n",
    "# select and save only the unique zip codes as referential list of zip \n",
    "apt_df = pd.read_csv(\"apartments.csv\",names = None, index_col=False)\n",
    "apt_df = apt_df.Zip.unique()\n",
    "zip = apt_df.tolist()\n",
    "\n",
    "# select income based on zipcodes in the \"zip\" list and save as df_match\n",
    "df_match = df_income[df_income['ZIPCODE'].isin(zip)] \n",
    "df_match = df_match[['A00100','ZIPCODE','N1','STATE']]\n",
    "df_match = df_match.rename(columns = {'ZIPCODE':'Zip','A00100':'Income','N1':'Num_of_Households'})\n",
    "df_match[['Income', 'Zip','Num_of_Households']] = df_match[['Income', 'Zip','Num_of_Households']].astype(int)\n",
    "\n",
    "#join df_match to df with \"Zip\" as the key to get df_full and save to csv file\n",
    "df = pd.read_csv('apartments_full.csv', names = None, index_col = False, encoding='ISO-8859-1')\n",
    "df_full = pd.merge(df,df_match[['Income','Zip','Num_of_Households']], on = [\"Zip\"], how = 'inner')\n",
    "df_full[['Zip','Num_of_Households']] = df_full[['Zip','Num_of_Households']].astype(int)\n",
    "df_full.to_csv('apartments_full.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Generating cordinates (latitude, longitude) according to address, using https://geocod.io/\n",
    "\n",
    "### Downing Metro Station lists of metro lines (json files) from https://developer.wmata.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# define function to get all json files in the current directory\n",
    "def getFileNames():\n",
    "    \"\"\"\n",
    "    Input = None\n",
    "    Returns = list of all JSON files in current directory\n",
    "    \"\"\"\n",
    "    import os\n",
    "    included_extenstions = ['json'] ;\n",
    "    file_names = [fn for fn in os.listdir(os.getcwd())\n",
    "        if any([fn.endswith(ext)\n",
    "        for ext in included_extenstions])];\n",
    "    return file_names\n",
    "\n",
    "# read json files and load data\n",
    "def readMetroData(file):\n",
    "    import json\n",
    "    with open(file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "# select only coordinates of stations on different lines from data\n",
    "def getCoords(metro_data):\n",
    "    metro_stations = [metro_data[line]['Stations'] for line in metro_data]\n",
    "    metro_stops = []\n",
    "    for i in range(len(metro_stations)):\n",
    "        metro_stops+= metro_stations[i]\n",
    "\n",
    "    coords = [(stop['Lat'],stop['Lon']) for stop in metro_stops]\n",
    "    return coords\n",
    "\n",
    "def readCSV(filename):\n",
    "    import csv\n",
    "    with open(filename, 'r') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        apartments = []\n",
    "        for row in reader:\n",
    "            apartments.append(row)\n",
    "    return apartments\n",
    "\n",
    "def calculateDistance(coord1, coord2):\n",
    "    import math\n",
    "    R = 6371000\n",
    "    latitude1 = coord1[0]\n",
    "    longitude1 = coord1[1]\n",
    "    \n",
    "    latitude2 = coord2[0]\n",
    "    longitude2 = coord2[1]\n",
    "    \n",
    "    lat1 = math.radians(latitude1)\n",
    "    lat2 = math.radians(latitude2)\n",
    "    delta_lat = math.radians(latitude1 - latitude2)\n",
    "    delta_lon = math.radians(longitude1 - longitude2)\n",
    "    \n",
    "    x = delta_lon * math.cos((lat1+lat2)/2)\n",
    "    y = delta_lat\n",
    "    d = math.sqrt(x*x + y*y) * R\n",
    "    return d\n",
    "\n",
    "def writeData(apartment_data):\n",
    "    import csv\n",
    "    with open('apartments_full.csv', 'w', newline = '') as f:\n",
    "        fieldnames = ['Name','Address','City','State','Zip','Style','Last update','Image count','Num bedrooms','Rent','Pets Allowed','Latitude','Longitude','Metro Distance','Income','Num_of_Households']\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for apt in apartment_data:\n",
    "            writer.writerow(apt)\n",
    "\n",
    "       \n",
    "    \n",
    "#codes to use functions defined above            \n",
    "files = getFileNames() \n",
    "\n",
    "#classify station lists in dictionaries of different metro lines\n",
    "metro_lines = {}\n",
    "for file in files:    \n",
    "    metro_lines[file.replace('Metro_','').replace('.json','')] = readMetroData(file)\n",
    "metro_coords = getCoords(metro_lines)\n",
    "\n",
    "#get all the coordinates of apartments to compare with that of metro stations and calculate distances\n",
    "apartments = readCSV('apartments_geocoded.csv')\n",
    "for apt in apartments:\n",
    "    distances = []\n",
    "    for station in metro_coords:\n",
    "        distances.append(calculateDistance((float(apt['Latitude']),float(apt['Longitude'])), station))\n",
    "    apt['Metro Distance'] = min(distances)\n",
    "    if min(distances) > 9041:\n",
    "        apt['Metro Distance'] = ''\n",
    "        \n",
    "#write Metro Distance column into csv file and rename it\n",
    "writeData(apartments)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# drop unrelated rows \n",
    "to_drop = ['CT', 'MI']\n",
    "df1 = df[~df['State'].isin(to_drop)]\n",
    "# clean out the null values and save it as 'apartments_nonull.csv'\n",
    "df1 = df[~df['Num bedrooms'].isnull()]\n",
    "df1 = df[~df['Rent'].isnull()]\n",
    "df1 = df[~df['Image count'].isnull()]\n",
    "df1 = df[~df['Image count'].isin(['Not specified'])]\n",
    "df1.to_csv('apartments_nonull.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
